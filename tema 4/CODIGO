"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [ import ply.lex as lex 

# Procesa componentes basicos de una expresion matematica unicamente

# Definición de tokens
tokens = ['Numero', 'Suma', 'Resta', 'Multi', 'Divi', 'Igual']

# Expresiones regulares para tokens nuestros tokens 
t_Suma = r'\+'
t_Resta = r'\-'
t_Multi = r'\*'
t_Divi = r'\/'
t_Igual = r'\='

# Expresión regular que reconoce números enteros
def t_Numero(t):
    r'\d+'
    t.value = int(t.value)
    return t

# Unicamente esta linea evita los espacios en blanco y/o saltos de linea 
t_ignore = ' \t'

# Regla para manejar los saltos de línea y actualizar el número de línea
def t_nuevalinea(t):
    r'\n+'
    t.lexer.lineno += len(t.value)

# En este apartado es en donde nosotros manejamos los errores 
def t_error(t):
    print("Carácter no válido: '%s'" % t.value[0])
    t.lexer.skip(1)

# Aqui vamos a construir nuestro analizador y poner los datos de los ejemplos de uso 
lexer = lex.lex()
data = "3 + 4 * 2\n7 - 5 \nb 5+5=0"    #IMPORTANTE
lexer.input(data)

# Función personalizada creada por el usuario para imprimir los tokens
def imprimir_token(token):
    print(f"Mi Token (tipo = {token.type},   valor = {token.value},   Linea Del Token = {token.lineno},   Posicion del token = {token.lexpos})")

# Aqui se imprimen los tokens que reconoce nuestro analizador 
while True:
    token = lexer.token()
    if not token:
        break
    imprimir_token(token) ]  ]
